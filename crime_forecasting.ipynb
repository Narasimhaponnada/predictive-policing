{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c2aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")\n",
    "print(f\"ðŸ“Š Pandas version: {pd.__version__}\")\n",
    "print(f\"ðŸ¤– NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94c71a1",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ada647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load crime data\n",
    "print(\"Loading LA Crime Data...\")\n",
    "df_raw = pd.read_csv('Crime_Data_from_2020_to_Present.csv')\n",
    "\n",
    "print(f\"âœ… Data loaded: {len(df_raw):,} records\")\n",
    "print(f\"\\nðŸ“Š Dataset shape: {df_raw.shape}\")\n",
    "print(f\"\\nðŸ“‹ Columns: {list(df_raw.columns)}\")\n",
    "print(f\"\\nðŸ” Sample data:\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2f150d",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0dc1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create working copy\n",
    "df = df_raw.copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸ§¹ DATA CLEANING FOR FORECASTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Keep only essential columns for forecasting\n",
    "essential_cols = [\n",
    "    'DATE OCC',      # Occurrence date\n",
    "    'TIME OCC',      # Occurrence time\n",
    "    'AREA',          # Area code\n",
    "    'AREA NAME',     # Area name\n",
    "    'Rpt Dist No',   # Reporting district\n",
    "    'Crm Cd',        # Crime code\n",
    "    'Crm Cd Desc',   # Crime description\n",
    "]\n",
    "\n",
    "df = df[essential_cols].copy()\n",
    "\n",
    "# Remove duplicates\n",
    "initial_count = len(df)\n",
    "df = df.drop_duplicates()\n",
    "duplicates_removed = initial_count - len(df)\n",
    "\n",
    "# Remove records with missing core features\n",
    "df = df.dropna(subset=['DATE OCC', 'AREA', 'Crm Cd Desc'])\n",
    "\n",
    "print(f\"âœ… Duplicates removed: {duplicates_removed:,}\")\n",
    "print(f\"âœ… Records with complete core data: {len(df):,}\")\n",
    "print(f\"\\nðŸ“Š Data retention: {len(df)/len(df_raw)*100:.1f}% of original data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681b17e",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering - Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69cfe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse dates and times\n",
    "print(\"=\"*80)\n",
    "print(\"â° EXTRACTING TEMPORAL FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df['DATE OCC'] = pd.to_datetime(df['DATE OCC'], errors='coerce')\n",
    "\n",
    "# Extract date components\n",
    "df['year'] = df['DATE OCC'].dt.year\n",
    "df['month'] = df['DATE OCC'].dt.month\n",
    "df['day'] = df['DATE OCC'].dt.day\n",
    "df['day_of_week'] = df['DATE OCC'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "df['day_name'] = df['DATE OCC'].dt.day_name()\n",
    "df['week_of_year'] = df['DATE OCC'].dt.isocalendar().week\n",
    "\n",
    "# Extract time components (CORRECTED METHOD)\n",
    "df['TIME_OCC_numeric'] = pd.to_numeric(df['TIME OCC'], errors='coerce')\n",
    "\n",
    "# Validate time ranges\n",
    "valid_time_mask = (\n",
    "    (df['TIME_OCC_numeric'] >= 0) & \n",
    "    (df['TIME_OCC_numeric'] <= 2359) &\n",
    "    ((df['TIME_OCC_numeric'] % 100) < 60)\n",
    ")\n",
    "\n",
    "# Extract hour correctly\n",
    "df['hour'] = np.where(\n",
    "    valid_time_mask,\n",
    "    (df['TIME_OCC_numeric'] // 100).astype(int),\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Create time blocks (3-hour windows for forecasting)\n",
    "def get_time_block(hour):\n",
    "    if pd.isna(hour):\n",
    "        return 'Unknown'\n",
    "    elif 0 <= hour < 3:\n",
    "        return '00-03_Late_Night'\n",
    "    elif 3 <= hour < 6:\n",
    "        return '03-06_Early_Morning'\n",
    "    elif 6 <= hour < 9:\n",
    "        return '06-09_Morning'\n",
    "    elif 9 <= hour < 12:\n",
    "        return '09-12_Late_Morning'\n",
    "    elif 12 <= hour < 15:\n",
    "        return '12-15_Afternoon'\n",
    "    elif 15 <= hour < 18:\n",
    "        return '15-18_Late_Afternoon'\n",
    "    elif 18 <= hour < 21:\n",
    "        return '18-21_Evening'\n",
    "    else:\n",
    "        return '21-00_Night'\n",
    "\n",
    "df['time_block'] = df['hour'].apply(get_time_block)\n",
    "\n",
    "# Additional temporal features\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "df['is_night'] = ((df['hour'] >= 18) | (df['hour'] <= 6)).fillna(0).astype(int)\n",
    "\n",
    "# Create date key for aggregation\n",
    "df['date'] = df['DATE OCC'].dt.date\n",
    "\n",
    "print(f\"âœ… Temporal features created\")\n",
    "print(f\"   Date range: {df['DATE OCC'].min()} to {df['DATE OCC'].max()}\")\n",
    "print(f\"   Valid times: {valid_time_mask.sum():,} ({valid_time_mask.sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"   Time blocks created: {df['time_block'].nunique()} unique blocks\")\n",
    "print(f\"\\nðŸ“Š Time block distribution:\")\n",
    "print(df['time_block'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b00d2",
   "metadata": {},
   "source": [
    "## 4. Create Crime Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156bfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify top crime types\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸŽ¯ CREATING CRIME CATEGORIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "crime_counts = df['Crm Cd Desc'].value_counts()\n",
    "top_n = 20\n",
    "top_crimes = crime_counts.head(top_n).index.tolist()\n",
    "\n",
    "# Create crime category\n",
    "df['crime_category'] = df['Crm Cd Desc'].apply(\n",
    "    lambda x: x if x in top_crimes else 'OTHER'\n",
    ")\n",
    "\n",
    "print(f\"âœ… Created {top_n + 1} crime categories (Top {top_n} + OTHER)\")\n",
    "print(f\"\\nðŸ“Š Top 10 Crime Categories:\")\n",
    "for i, (crime, count) in enumerate(df['crime_category'].value_counts().head(10).items(), 1):\n",
    "    print(f\"   {i:2d}. {crime[:50]:50s} {count:>7,} ({count/len(df)*100:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7865b396",
   "metadata": {},
   "source": [
    "## 5. CRITICAL STEP: Aggregate Data for Forecasting\n",
    "\n",
    "This is where we transform from individual crime records to forecasting format:\n",
    "- Group by: Area + Date + Time Block\n",
    "- Aggregate: Count total crimes, count by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f7954",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ðŸ”„ AGGREGATING DATA FOR FORECASTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create aggregation keys\n",
    "df['area_name_clean'] = df['AREA NAME'].fillna('Unknown')\n",
    "\n",
    "# Aggregate by area, date, and time block\n",
    "print(\"Aggregating crime counts by Area + Date + Time Block...\")\n",
    "\n",
    "# Total crime count per area/date/time_block\n",
    "df_agg = df.groupby(['area_name_clean', 'date', 'time_block']).agg({\n",
    "    'Crm Cd': 'count',  # Total crimes\n",
    "    'AREA': 'first',    # Area code\n",
    "    'year': 'first',\n",
    "    'month': 'first',\n",
    "    'day': 'first',\n",
    "    'day_of_week': 'first',\n",
    "    'is_weekend': 'first',\n",
    "}).reset_index()\n",
    "\n",
    "df_agg = df_agg.rename(columns={'Crm Cd': 'crime_count'})\n",
    "\n",
    "# Crime type distribution per area/date/time_block\n",
    "crime_type_pivot = df.groupby(['area_name_clean', 'date', 'time_block', 'crime_category']).size().unstack(fill_value=0)\n",
    "\n",
    "# Merge back\n",
    "df_agg = df_agg.merge(\n",
    "    crime_type_pivot,\n",
    "    left_on=['area_name_clean', 'date', 'time_block'],\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… TRANSFORMATION COMPLETE\")\n",
    "print(f\"   Original records: {len(df):,} individual crimes\")\n",
    "print(f\"   Aggregated records: {len(df_agg):,} time windows\")\n",
    "print(f\"   Unique areas: {df_agg['area_name_clean'].nunique()}\")\n",
    "print(f\"   Date range: {df_agg['date'].min()} to {df_agg['date'].max()}\")\n",
    "print(f\"   Time blocks: {df_agg['time_block'].nunique()}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Sample aggregated data:\")\n",
    "df_agg.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd8170",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering for Forecasting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ec58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ðŸ”§ ENGINEERING FORECASTING FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sort by area and date for time-series features\n",
    "df_agg = df_agg.sort_values(['area_name_clean', 'date', 'time_block'])\n",
    "\n",
    "# Create lagged features (past crime counts)\n",
    "print(\"Creating historical crime features...\")\n",
    "\n",
    "for area in df_agg['area_name_clean'].unique():\n",
    "    area_mask = df_agg['area_name_clean'] == area\n",
    "    \n",
    "    # Lag features (previous day's crime count)\n",
    "    df_agg.loc[area_mask, 'crime_count_lag1'] = df_agg.loc[area_mask, 'crime_count'].shift(1)\n",
    "    df_agg.loc[area_mask, 'crime_count_lag7'] = df_agg.loc[area_mask, 'crime_count'].shift(7)\n",
    "    \n",
    "    # Rolling averages\n",
    "    df_agg.loc[area_mask, 'crime_count_rolling_7'] = df_agg.loc[area_mask, 'crime_count'].rolling(window=7, min_periods=1).mean()\n",
    "    df_agg.loc[area_mask, 'crime_count_rolling_30'] = df_agg.loc[area_mask, 'crime_count'].rolling(window=30, min_periods=1).mean()\n",
    "\n",
    "# Fill NaN in lag features with 0 (for initial periods)\n",
    "df_agg[['crime_count_lag1', 'crime_count_lag7', 'crime_count_rolling_7', 'crime_count_rolling_30']] = \\\n",
    "    df_agg[['crime_count_lag1', 'crime_count_lag7', 'crime_count_rolling_7', 'crime_count_rolling_30']].fillna(0)\n",
    "\n",
    "# Encode categorical variables\n",
    "le_area = LabelEncoder()\n",
    "le_timeblock = LabelEncoder()\n",
    "\n",
    "df_agg['area_encoded'] = le_area.fit_transform(df_agg['area_name_clean'])\n",
    "df_agg['time_block_encoded'] = le_timeblock.fit_transform(df_agg['time_block'])\n",
    "\n",
    "print(f\"\\nâœ… Forecasting features created\")\n",
    "print(f\"   Lag features: 2 (lag1, lag7)\")\n",
    "print(f\"   Rolling features: 2 (7-day, 30-day averages)\")\n",
    "print(f\"   Encoded features: 2 (area, time_block)\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Feature summary:\")\n",
    "print(f\"   Total features: {df_agg.shape[1]}\")\n",
    "print(f\"   Records ready for modeling: {len(df_agg):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b4e97",
   "metadata": {},
   "source": [
    "## 7. Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a1547",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ðŸ“¦ PREPARING TRAINING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select features for model\n",
    "feature_cols = [\n",
    "    'area_encoded',\n",
    "    'time_block_encoded',\n",
    "    'year',\n",
    "    'month',\n",
    "    'day',\n",
    "    'day_of_week',\n",
    "    'is_weekend',\n",
    "    'crime_count_lag1',\n",
    "    'crime_count_lag7',\n",
    "    'crime_count_rolling_7',\n",
    "    'crime_count_rolling_30'\n",
    "]\n",
    "\n",
    "# Target variable: crime_count\n",
    "target_col = 'crime_count'\n",
    "\n",
    "# Remove rows with any NaN values\n",
    "df_model = df_agg[feature_cols + [target_col]].dropna()\n",
    "\n",
    "X = df_model[feature_cols]\n",
    "y = df_model[target_col]\n",
    "\n",
    "# Time-series split (train on past, test on future)\n",
    "# Use 80% for training, 20% for testing\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"âœ… Data prepared for modeling\")\n",
    "print(f\"\\nðŸ“Š Data Split:\")\n",
    "print(f\"   Training set: {len(X_train):,} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   Test set: {len(X_test):,} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nðŸ“‹ Features: {len(feature_cols)}\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "print(f\"\\nðŸŽ¯ Target: {target_col}\")\n",
    "print(f\"   Min: {y_train.min()}, Max: {y_train.max()}, Mean: {y_train.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adea48f9",
   "metadata": {},
   "source": [
    "## 8. Train XGBoost Regression Model\n",
    "\n",
    "### Is XGBoost Right for Crime Forecasting?\n",
    "\n",
    "**YES! XGBoost is EXCELLENT for this use case:**\n",
    "\n",
    "âœ… **Regression Mode** - XGBRegressor predicts crime counts (continuous values)\n",
    "âœ… **Handles Temporal Features** - Excellent with lag features and rolling averages\n",
    "âœ… **Non-Linear Patterns** - Captures complex time/area interactions\n",
    "âœ… **Feature Importance** - Shows which factors drive crime counts\n",
    "âœ… **Fast Prediction** - Real-time forecasting for police deployment\n",
    "\n",
    "**Alternative Models to Consider:**\n",
    "- Prophet (Facebook's time-series tool) - Better for pure time-series\n",
    "- ARIMA/SARIMA - Traditional time-series forecasting\n",
    "- Random Forest Regressor - Similar performance, more interpretable\n",
    "- Neural Networks (LSTM) - Better for sequential patterns, needs more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fff746",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ðŸš€ TRAINING XGBOOST REGRESSION MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize XGBoost Regressor\n",
    "model = XGBRegressor(\n",
    "    objective='reg:squarederror',  # Regression objective\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Model training complete!\")\n",
    "print(f\"\\nðŸ“Š Model Configuration:\")\n",
    "print(f\"   Objective: Crime Count Regression\")\n",
    "print(f\"   Trees: {model.n_estimators}\")\n",
    "print(f\"   Max depth: {model.max_depth}\")\n",
    "print(f\"   Learning rate: {model.learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da085fb8",
   "metadata": {},
   "source": [
    "## 9. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ede7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ðŸ“ˆ MODEL EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ REGRESSION METRICS:\")\n",
    "print(f\"\\n   Training Set:\")\n",
    "print(f\"      MAE (Mean Absolute Error): {train_mae:.2f} crimes\")\n",
    "print(f\"      RMSE (Root Mean Squared Error): {train_rmse:.2f} crimes\")\n",
    "print(f\"      RÂ² Score: {train_r2:.4f}\")\n",
    "\n",
    "print(f\"\\n   Test Set:\")\n",
    "print(f\"      MAE (Mean Absolute Error): {test_mae:.2f} crimes\")\n",
    "print(f\"      RMSE (Root Mean Squared Error): {test_rmse:.2f} crimes\")\n",
    "print(f\"      RÂ² Score: {test_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ Interpretation:\")\n",
    "print(f\"   On average, predictions are off by Â±{test_mae:.1f} crimes\")\n",
    "print(f\"   Model explains {test_r2*100:.1f}% of crime count variance\")\n",
    "\n",
    "# Visualize predictions vs actual\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Actual vs Predicted\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.3, s=10)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Crime Count')\n",
    "plt.ylabel('Predicted Crime Count')\n",
    "plt.title('Actual vs Predicted Crime Counts')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y_test - y_test_pred\n",
    "plt.hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Prediction Error (Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Prediction Errors')\n",
    "plt.axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… Evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30ea342",
   "metadata": {},
   "source": [
    "## 10. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ðŸ” FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š Top Features for Crime Count Prediction:\")\n",
    "for i, row in feature_importance.iterrows():\n",
    "    print(f\"   {row['feature']:30s} {row['importance']:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Feature Importance for Crime Count Prediction')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Feature importance analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e5ce7",
   "metadata": {},
   "source": [
    "## 11. Crime Forecasting Interface\n",
    "\n",
    "This is the key deliverable: A function that takes Area + Time and predicts crime counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a2340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_crime_count(area_name, date_str, time_block):\n",
    "    \"\"\"\n",
    "    Predict crime count for a given area, date, and time block.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    area_name : str\n",
    "        Area name (e.g., 'Central', 'Hollywood')\n",
    "    date_str : str\n",
    "        Date in format 'YYYY-MM-DD'\n",
    "    time_block : str\n",
    "        Time block (e.g., '18-21_Evening', '00-03_Late_Night')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Prediction results with crime count and confidence interval\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parse input\n",
    "    date = pd.to_datetime(date_str)\n",
    "    \n",
    "    # Check if area exists\n",
    "    if area_name not in le_area.classes_:\n",
    "        return {\"error\": f\"Area '{area_name}' not found. Available areas: {list(le_area.classes_)}\"}\n",
    "    \n",
    "    # Check if time block exists\n",
    "    if time_block not in le_timeblock.classes_:\n",
    "        return {\"error\": f\"Time block '{time_block}' not found. Available blocks: {list(le_timeblock.classes_)}\"}\n",
    "    \n",
    "    # Encode inputs\n",
    "    area_encoded = le_area.transform([area_name])[0]\n",
    "    time_block_encoded = le_timeblock.transform([time_block])[0]\n",
    "    \n",
    "    # Get historical data for this area and time block\n",
    "    hist_data = df_agg[\n",
    "        (df_agg['area_name_clean'] == area_name) &\n",
    "        (df_agg['time_block'] == time_block)\n",
    "    ].tail(30)  # Last 30 occurrences\n",
    "    \n",
    "    # Calculate lag and rolling features\n",
    "    crime_count_lag1 = hist_data['crime_count'].iloc[-1] if len(hist_data) > 0 else 0\n",
    "    crime_count_lag7 = hist_data['crime_count'].iloc[-7] if len(hist_data) >= 7 else 0\n",
    "    crime_count_rolling_7 = hist_data['crime_count'].tail(7).mean() if len(hist_data) >= 7 else 0\n",
    "    crime_count_rolling_30 = hist_data['crime_count'].tail(30).mean() if len(hist_data) > 0 else 0\n",
    "    \n",
    "    # Create feature vector\n",
    "    features = pd.DataFrame([{\n",
    "        'area_encoded': area_encoded,\n",
    "        'time_block_encoded': time_block_encoded,\n",
    "        'year': date.year,\n",
    "        'month': date.month,\n",
    "        'day': date.day,\n",
    "        'day_of_week': date.dayofweek,\n",
    "        'is_weekend': 1 if date.dayofweek >= 5 else 0,\n",
    "        'crime_count_lag1': crime_count_lag1,\n",
    "        'crime_count_lag7': crime_count_lag7,\n",
    "        'crime_count_rolling_7': crime_count_rolling_7,\n",
    "        'crime_count_rolling_30': crime_count_rolling_30\n",
    "    }])\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_count = model.predict(features)[0]\n",
    "    \n",
    "    # Calculate confidence interval (Â±1 MAE)\n",
    "    lower_bound = max(0, predicted_count - test_mae)\n",
    "    upper_bound = predicted_count + test_mae\n",
    "    \n",
    "    return {\n",
    "        'area': area_name,\n",
    "        'date': date_str,\n",
    "        'time_block': time_block,\n",
    "        'predicted_crime_count': round(predicted_count, 1),\n",
    "        'confidence_interval': f\"{round(lower_bound, 1)} - {round(upper_bound, 1)} crimes\",\n",
    "        'historical_avg': round(crime_count_rolling_30, 1),\n",
    "        'trend': 'Increasing' if predicted_count > crime_count_rolling_30 else 'Decreasing'\n",
    "    }\n",
    "\n",
    "print(\"âœ… Crime forecasting interface created!\")\n",
    "print(\"\\nðŸ“‹ Available functions:\")\n",
    "print(\"   predict_crime_count(area_name, date_str, time_block)\")\n",
    "print(\"\\nðŸ’¡ Example usage:\")\n",
    "print(\"   result = predict_crime_count('Central', '2026-01-15', '18-21_Evening')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4af49",
   "metadata": {},
   "source": [
    "## 12. Example Predictions - Test the System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ðŸŽ¯ EXAMPLE CRIME FORECASTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get available areas\n",
    "available_areas = df_agg['area_name_clean'].unique()[:5]  # First 5 areas\n",
    "\n",
    "# Test predictions\n",
    "test_date = '2026-01-15'\n",
    "test_scenarios = [\n",
    "    (available_areas[0], test_date, '18-21_Evening'),\n",
    "    (available_areas[0], test_date, '00-03_Late_Night'),\n",
    "    (available_areas[1], test_date, '12-15_Afternoon'),\n",
    "    (available_areas[2], test_date, '06-09_Morning'),\n",
    "]\n",
    "\n",
    "print(f\"\\nðŸ“Š Forecasts for {test_date}:\\n\")\n",
    "\n",
    "for area, date, time_block in test_scenarios:\n",
    "    result = predict_crime_count(area, date, time_block)\n",
    "    \n",
    "    if 'error' not in result:\n",
    "        print(f\"ðŸ”® {area} - {time_block}\")\n",
    "        print(f\"   Expected crimes: {result['predicted_crime_count']}\")\n",
    "        print(f\"   Range: {result['confidence_interval']}\")\n",
    "        print(f\"   Trend: {result['trend']} (vs avg: {result['historical_avg']})\")\n",
    "        print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"âœ… FORECASTING SYSTEM READY FOR DEPLOYMENT\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3f864c",
   "metadata": {},
   "source": [
    "## 13. Summary & Next Steps\n",
    "\n",
    "### What We Built:\n",
    "âœ… **Crime Count Forecasting Model** - Predicts how many crimes will occur\n",
    "âœ… **XGBoost Regression** - Optimized for temporal and spatial patterns\n",
    "âœ… **Prediction Interface** - Easy to use: input area + time â†’ get crime forecast\n",
    "âœ… **Feature Engineering** - Lag features, rolling averages, temporal patterns\n",
    "\n",
    "### Model Performance:\n",
    "- Predicts crime counts with reasonable accuracy\n",
    "- Captures temporal patterns (time of day, day of week)\n",
    "- Accounts for geographic variation (area differences)\n",
    "- Uses historical trends for better predictions\n",
    "\n",
    "### Why XGBoost is Right:\n",
    "âœ… **Regression capability** - Predicts continuous counts\n",
    "âœ… **Handles temporal features** - Excellent with lag and rolling features\n",
    "âœ… **Non-linear patterns** - Captures complex time/area interactions\n",
    "âœ… **Fast inference** - Real-time predictions for police operations\n",
    "âœ… **Feature importance** - Shows what drives crime patterns\n",
    "\n",
    "### Next Steps:\n",
    "1. **Crime Type Distribution** - Add model to predict WHAT types of crimes\n",
    "2. **Hyperparameter Tuning** - Optimize XGBoost parameters\n",
    "3. **More Features** - Add weather, events, holidays\n",
    "4. **Ensemble Methods** - Combine with Prophet/ARIMA for better accuracy\n",
    "5. **Deployment** - Create API for police department integration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crime-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
